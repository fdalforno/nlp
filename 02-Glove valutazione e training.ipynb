{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d8d567",
   "metadata": {},
   "source": [
    "# Ripasso\n",
    "\n",
    "https://datascience.stackexchange.com/questions/20071/how-do-i-load-fasttext-pretrained-model-with-gensim\n",
    "\n",
    "Durante l'addestramento di un modello per creare gli embeddings abbiamo eseguito i seguenti passi:\n",
    "* siamo partiti con dei vettori di embeddings random\n",
    "* abbiamo letto tutte le parole del corpus\n",
    "* abbiamo predetto il contesto con la parola di origine mediante il seguente schema:\n",
    "![skipgram](./images/window.png)\n",
    "\n",
    "\n",
    "Questo modello crea la stessa previsione senza occuparsi della posizione della parola (bag of word). \n",
    "Questo è un metodo molto semplificato, ci muoveremo su modelli più complessi, ma è abbastanza potente da poter catturare dei problemi base.\n",
    "\n",
    "L'obiettivo del word2vec è quello di posizionare \"vicino\" parole simili.\n",
    "\n",
    "## Ottimizzazione: Gradient descent\n",
    "\n",
    "Per creare dei buoni word vector dobbiamo minimizzare una funzione di costo $J(\\theta)$, il gradient descent è un algoritmo che minimizza $J(\\theta)$ cambiando i valori di $\\theta$.\n",
    "L'idea su cui si basa è la seguente, dal valaore attuale di $\\theta$ calcoliamo una stima del gradiente di $J(\\theta)$ e facciamo un piccolo passo nella direzione opposta del gradiente, via così finche non otteniamo miglioramenti significativi.\n",
    "\n",
    "![gradient](./images/gradient.png)\n",
    "\n",
    "Nota bene: la funzione potrebbe non essere convessa come nella immagine sopra \n",
    "\n",
    "L'ottimizzazione è particolarmente costosa dobbiamo trovare dei metodi per abbassare il costo computazionale.\n",
    "Il primo metodo applicabile è lo stocastic gradiend, creiamo dei minibatch e applichiamo l'ottimizzazione a quel batch.\n",
    "\n",
    "Applicando il **negative subsampling**.\n",
    "\n",
    "## Skipgram con il negative subsampling\n",
    "\n",
    "Nella funzione di costo il termine di normalizzazione è particolarmente costoso, dobbiamo usare l'intero dizionario.\n",
    "In nostro soccorso viene negative sampling, che rappresenta una approssimazione del [Noise-Contrast Estimation](https://www.kdnuggets.com/2019/07/introduction-noise-contrastive-estimation.html).\n",
    "\n",
    "L'idea che sta dietro a questo sistema è invece di passare su tutte le parole non corrette (il cui peso sul vettore finale deve avere valore 0) ne prendiamo solo un pò. \n",
    "Queste parole scelte vengono chiamate (negative sample) ora invece che normalizzare su tutto il vocabolario useremo solo i termini scelti nel sample più il termine corretto.\n",
    "\n",
    "La distribuzione da cui andremo a campionare le parole verrà chiamata noise distribution $P_n(w)$ le cui probabilità corrispondono all'ordinamento della frequenza del vocabolario.\n",
    "\n",
    "Consideriamo ora una coppia di parole $(w,c)$ questa coppia appartiene ai dati di training? Rappresentiamo $P(D = 1 | w,c)$ la probabilità che $w$ e $c$ appartengano al corpus dei dati. \n",
    "Se invece scriviamo $P(D = 0 | w,c)$ stiamo rappresentando la probabilità che la coppia non appartenga al nostro corpus.\n",
    "\n",
    "Come prima cosa modelliamo $P(D = 1 | w,c)$ con una sigmoide:\n",
    "\n",
    "$$P(D = 1 | w,c,\\theta) = \\theta(v_c^T v_w) = \\frac{1}{1 + e^{- v_c^T v_w}} $$\n",
    "\n",
    "Ora modifichiamo la funzione di costo affinchè massimizzi la probabilità che una parola appartenga al corpus se lo è e che massimizzi la probabilità che una parola non sia nel corpus se non lo è.\n",
    "\n",
    "Procediamo con un semplice approccio per verosomiglianza.\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "    \\theta & = argmax_{\\theta} \\prod_{(w,c) \\in D} P(D = 1 | w,c,\\theta) \\prod_{(w,c) \\in \\overline{D}} P(D = 0 | w,c,\\theta) \\\\\n",
    "           & = argmax_{\\theta} \\prod_{(w,c) \\in D} P(D = 1 | w,c,\\theta) \\prod_{(w,c) \\in \\overline{D}} 1 - P(D = 1 | w,c,\\theta) \\\\\n",
    "           & = argmax_{\\theta} \\sum_{(w,c) \\in D} log P(D = 1 | w,c,\\theta) + \\sum_{(w,c) \\in \\overline{D}} log 1 - P(D = 1 | w,c,\\theta) \\\\\n",
    "           & = argmax_{\\theta} \\sum_{(w,c) \\in D} log \\frac{1}{1 + e^{- v_c^T v_w}} + \\sum_{(w,c) \\in \\overline{D}} log(1 - \\frac{1}{1 + e^{- v_c^T v_w}}) \\\\ \n",
    "            & = argmax_{\\theta} \\sum_{(w,c) \\in D} log \\frac{1}{1 + e^{- v_c^T v_w}} + \\sum_{(w,c) \\in \\overline{D}} log( \\frac{1}{1 + e^{v_c^T v_w}}) \\\\ \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "massimizzare la funzione di costo di cui sopra è lo stesso che minimizzare la funzione qui sotto:\n",
    "\n",
    "$$ J =  \\sum_{(w,c) \\in D} log \\frac{1}{1 + e^{- v_c^T v_w}} - \\sum_{(w,c) \\in \\overline{D}} log( \\frac{1}{1 + e^{v_c^T v_w}}) $$\n",
    "\n",
    "La lettera $\\overline{D}$ rappresenta il corpus negativo ovvero tutte quelle frasi che non hanno senso. Si può generare $\\overline{D}$ al volo campionando parole a caso sul nostro dataset.\n",
    "\n",
    "Per il nostro modello skipgram la nostra funzione obiettivo della parola di contesto $c - m + j$ e della parola centrale $c$ diventa:\n",
    "\n",
    "$$\n",
    "-log \\sigma(u^{T}_{c - m + j} \\cdot v_c) - \\sum_{k=1}^{K} log \\sigma(- \\overline{u}_{k}^{T} \\cdot v_c)\n",
    "$$\n",
    "\n",
    "In questa formulazione ${\\overline{u}_{k} | k = 1 \\cdots K}$ è un campione di $P_n(w)$, come dovrebbe essere questa distribuzione ? Se ne è discusso molto ciò che sembra funzionare meglio è il modello unigram elevato alla potenza di 3/4.\n",
    "\n",
    "Ma perchè proprio 3/4 ? Facciamo qualche esempio:\n",
    "\n",
    "is = $0.9^{3/4}$ = $0.92$\n",
    "costitution = $0.09^{3/4}$ = $0.16$\n",
    "bombastic = $0.01^{3/4}$ = $0.032$\n",
    "\n",
    "il termine bombastic dopo l'elevamento a potenza ha 3 volte la probabilità di essere scelto mentre is ha avuto un incremento parziale.\n",
    "\n",
    "## Introduzione a Glove\n",
    "\n",
    "Ora vedendo anche gli esercizi fatti possiamo chiederci perchè un contesto locale come fatto negli esempi precedenti non andiamo ad utilizzare una matrice globale ed applicare un metodo di fattorizzazione? \n",
    "\n",
    "I metodi di fattorizzazione globale affrontano efficacemente la statistica globale del corpus ma non gestiscono bene le analogie. D'altro canto i modelli che lavorano sul contesto locale lavorano bene con le analogie ma non utilizzano la statistica globale del corpus, lasciando spazio per miglioramenti.\n",
    "\n",
    "Glove cerca di prendere il meglio da entrambi gli approcci, con un approccio che efficentemente sfrutta la statistica globale del corpus mentre ottimizza un modello che usa basato sul contesto.\n",
    "\n",
    "### Matrice di co occorrenza\n",
    "Denotiamo come $X$ la matrice di co occorrenza dove $X_{i,j}$ indica il numero di volte che la parola i appare nel contesto della parola j. \n",
    "Sia $X_i = \\sum_k X_{i,k}$ il numero delle volte che ogni parola $k$ appare nel contesto della parola $i$, impostiamo poi la seguente dicitura come \n",
    "\n",
    "$$P_{i,j} = P(w_i|w_j) = \\frac{X_{i,j}}{X_{i}}$$\n",
    "\n",
    "la probabilità che la parola $w_i$ appaia nel contesto della parola $w_j$\n",
    "Popolare questa matrice richiede un singolo passaggio di tutto il corpus per raccogliere tutta la statistica, per corpus molto grandi questa operazione può risultare costosa ma è soltanto un costo iniziale una tantum.\n",
    "\n",
    "### Funzione obiettivo dei minimi quadrati\n",
    "Nell'ultimo modello abbiamo usato la funzione softmax per calcolare la probabilità che la parola $j$ appaia nel contesto della parola $i$\n",
    "\n",
    "$$Q_{i,j} = \\frac{exp\\left(\\vec{u_j}^{T} \\vec{v}_i \\right)}{\\sum_{w=1}^{W} exp\\left(\\vec{u_w}^{T} \\vec{v}_i \\right)}$$\n",
    "\n",
    "La procedura di training procede come come fatto prima con il processo di gradient stocastico, la funzione di costo globale può essere usata come una funzione di costo cross-entropy globale:\n",
    "\n",
    "$$J =  -\\sum_{i \\in corpus} \\sum_{j \\in context(i)} log Q_{i,j}$$\n",
    "\n",
    "\n",
    "Poiche le stesse parole i e j possono apparire più volte nel corpus, risulta più efficiente \n",
    "\n",
    "### Conclusione\n",
    "In conclusione il modello glove sfrutta in modo efficiente la statistica globale, produce un sottospazio vettoria con sotto strutture significative. Produce risultati migliori rispetto alle tecniche viste precedentemente e più velocemente. \n",
    "\n",
    "# Valutazione dei word vectors\n",
    "\n",
    "Abbiamo discusso dei metodi di creazione dei word vectors e di come si esegue la fase di training. In questa sezione discuteremo di come possiamo valutare quantitativamente la qualità dei vettori prodotti per ogni tecnica vista.\n",
    "\n",
    "## Valutazione intrinseca\n",
    "\n",
    "La valutazione intrinseca di un word vectors è la valutazione di un insieme di word vectors generati con con una tecnica qualsiasi di embeddings su uno specifico sottotask intermedio (come ad esempio un completamento di una analogia).\n",
    "\n",
    "Questi sottotask sono operazioni tipicamente semplici e veloci da calcolare e ci aiutano a capire il sistema usato per per generare i vettori.\n",
    "\n",
    "Una valutazione intrinseca può tipicamente ritornarci un valore che indica le performance del nostro word vectors sul sottotask di valutazione.\n",
    "\n",
    "**Motivazione:** prendiamo in considerazione un esempio il cui nostro obiettivo finale è quello di creare un sistema di question answering che usa questi word vectors come input. Un possibile approccio è quello di eseguire un train su un sistema composto in questo modo:\n",
    "\n",
    "1. Prende come input le parole\n",
    "2. Converte le parole in vettori \n",
    "3. Usa questi vettori per eseguire delle lavorazioni\n",
    "4. Mappa le parole di output calcolate in linguaggio natuale\n",
    "5. Produce una serie di parole delle risposta\n",
    "\n",
    "Questo sistema al suo stato d'arte, ha bisogno di una rappresentazione dei word vectors ottimale, poichè verrà utilizzata nei sottosistemi a valle.\n",
    "Per fare questo in pratica abbiamo bisogno di impostare correttamente una marea di hyperparameters del sistema Word2Vec.\n",
    "Mentre l'approccio idealistico è quello di eseguire un intero retrain del word2vec ad ogni cambiamento di un iperparametro, questo da un punto di vista ingegneristico è impraticabile in quanto già il passo 3 di solito è rappresentato da un sistema di deep learning con milioni di parametri che hanno bisogno di lunghe fasi di training.\n",
    "\n",
    "In questa situazione abbiamo bisogno di una semplice tecnica di valutazione intrinseca che ci fornisca una misura della bonta dei word verctors. Ovviamente il requisito è che la valutazione intrinseca abbia una correlazione positiva con le performance del task finale.\n",
    "\n",
    "## Valutazione Estrinseca\n",
    "\n",
    "La valutazione estrinseca dei word vectors è la valutazione di un sottoinsieme di vettori generati dal sistema di embedding sul task reale. Questa attività è tipicamente elaborata e lenta da calcolare. Riprendendo l'esempio sopra un sistema che permette di valutare le risposte date è un esempio di valutazione estrinseca.\n",
    "\n",
    "In genere una perfomance non ottimale su un sistema di valutazione estrinseca non permette di determinare quale parte del sistema sta avendo dei problemi. Questo ci spiega il perchè abbiamo bisogno di una valutazione intriseca.\n",
    "\n",
    "### Esempio di valutazione intrinseca (Analogie)\n",
    "\n",
    "Una scelta popolare per la valutazione di un insieme di word vectors sta nel monitorare le performance sul completamento delle analogie. \n",
    "\n",
    "In questa attività viene fornito una analogia incompleta nella forma:\n",
    "\n",
    "a::b::c::?\n",
    "\n",
    "Il sistema di verifica delle analogie dati a,b,c identifica il vettore che minizza la formula (somiglianza del coseno):\n",
    "\n",
    "$$d = argmax_i \\frac{(x_b - x_a + x_c)^{T}x_i}{\\lVert x_b - x_a + x_c \\rVert}$$\n",
    "\n",
    "questa metrica ha una interpretazione intuitiva, idealmente vogliamo che $x_b -x_a = x_d - x_c$ per esempio (queen - king = actress - actor). Questo significa che $x_b - x_a + x_c =  x_d$ quindi identifichiamo il vettore $x_d$ che minimizza il prodotto scalare normalizzato tra i due vettori di parole.\n",
    "\n",
    "## Affrontare l'ambiguità\n",
    "\n",
    "Una domande che possiamo porci potrebbe essere: come gestiamo le parole con più significati ? Ad esempio \"run\" è sia un nome che un verbo e viene utilizzato e interpretato in base al contesto. Nel seguente paper **[Improving Word Representations Via Global Context And Multiple Word Prototypes (Huang et al, 2012)]** descrive come questi casi possono essere gestiti:\n",
    "\n",
    "1. Raccogliere le context windows per tutte le evenienze della parola in questione \n",
    "2. Ogni contesto viene rappresentato dalla media pesata dei word vector del contesto\n",
    "3. Applico un k-mean sferico per calcolare i cluster che rappresentano i vari contesti\n",
    "4. Alla fine per ogni occorrenza della parola viene eseguito in indirizzamento verso il cluster corretto e uso questo per eseguire l'embeddings\n",
    "\n",
    "## Training su task estrinsechi\n",
    "\n",
    "Abbiamo appena discusso sui task intrisechi e abbiamo enfatizzato l'importanza di questo per sviluppare buone tecniche di embeddings. \n",
    "\n",
    "Ovviamente il nostro obiettivo finale, nei problemi della vita reale è quello di valutare i risultati del word vectoring per altri task estrinsechi. \n",
    "Qui discutiamo un approccio generale per gestire questi task.\n",
    "\n",
    "### Formulazione del problema\n",
    "\n",
    "Molte attività di NLP possono essere formulate come task di classificazione. Per esempio data una frase possiamo dire se questa rappresenta una opinione (sentiment) positiva, neutrale o negativa. Similmente se stiamo eseguendo una attività di NER (Named Entity Recognition) dato un contesto e una parola centrale vogliamo classificarla in una delle classi volute.\n",
    "\n",
    "Facciamo un esempio pratico con la frase : \"Jim bought 300 shares of Acme Corp. in 2006\" vorremmo come risultato \"[Jim] ___Person___ bought 300 shares of [Acme Corp.] ___Organization___ in [2006] ___Time___ .\n",
    "\n",
    "Per questi problemi tipicamente iniziamo con un set di training nella forma seguente:\n",
    "\n",
    "$$ \\{ x^i,y^i \\}^{N}_i$$\n",
    "\n",
    "Dove $x^i$ è un vettore di embeddings con dimensione d mentre $y^i$ è un vettore one hot con dimensione C che indica l'etichetta che vorremmo ricevere.\n",
    "\n",
    "In una attività tipica di machine learning usualmente si prendono in ingresso i dati di input e con le nostre etichette eseguiamo una fase di training con tecniche di ottimizzazione.\n",
    "\n",
    "Nel nostro problema di NLP però introduciamo l'idea di riaddestrare i word vectors di input per poi eseguire il train per risolvere il nostro problema.\n",
    "\n",
    "Discutiamo del come e del quando considerare questa opzione.\n",
    "\n",
    "### Retraining Word Vectors\n",
    "\n",
    "Come abbiamo visto i word vectors che usiamo per le operazioni estrinseche possono essere creati tramite l'ottimizzazione su task intrinsechi.\n",
    "\n",
    "In molti casi l'uso dei word vectors pretrained sono un ottimo sono dei validi sostituti dei word vectors per quel task.\n",
    "E' possibile comunque che quei vettori possano essere migliorati esguendo ulteriori fasi di training. Attenzione fare un retrain dei word vectors può essere rischioso.\n",
    "\n",
    "Se eseguiamo un retrain dei word vectors usando il task estrinseco dobbiamo assicurarci che il dataset di training sia grande abbastanza da coprire la grande maggioranza delle parole del vocabolario.\n",
    "\n",
    "Questo perchè i sistemi di embeddings visti prima producono parole semanticamente collegate in base al contesto.\n",
    "Quando eseguiamo il retrain su un dataset piccolo, i vettori verranno spostati nello spazio come risultato e le performance finali potrebbero risentirne.\n",
    "\n",
    "Vediamo questo concetto nel dettaglio, supponiamo di avere un insieme di vettori pretrained in due dimensioni come nella immagine sottostante.\n",
    "\n",
    "![Two dim](./images/pretrained_vectors.png)\n",
    "\n",
    "Vediamo che il task di classificazione delle parole Telly, TV e television esegue correttamente il lavoro. Ora supponiamo di voler esegure il retrain dei vettori e che la parola Television sia presente solo nel dataset di test. Sappiamo che le parole TV e Telly saranno messe vicine, ma per il fatto che la parola Television sia poco presente questa verrà allontanata dalle altre.\n",
    "Il risultato molto probabilmente sarà quello sottostante.\n",
    "\n",
    "![Two dim](./images/pretrained_vectors_overfitting.png)\n",
    "\n",
    "Questo ci può dare una idea del fatto che i word vectors non debbano essere riaddestrati se il dataset è piccolo, altro discorso se siamo di fronte ad un dataset grande. In questo caso eseguire il training dei word vectors può portare a un miglior risultato finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc7ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
