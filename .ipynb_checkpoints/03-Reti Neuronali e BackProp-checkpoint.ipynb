{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99745be0",
   "metadata": {},
   "source": [
    "In questa lezione ci concetriamo sulla matematica dietro alle reti neuronali.\n",
    "Prendiamo come esempio l'attività di classificazione dei nomi nel testo come ad esempio:\n",
    "\n",
    "![ner](./images/ner.png)\n",
    "\n",
    "Questo sistema viene utilizzato per:\n",
    "* Tracciare le menzioni di particolari entità nei documenti\n",
    "* Nei sistemi di question answering, in quanto spesso le risposte sono named entities\n",
    "\n",
    "Spesso questo viene seguito da una analisi Entity Linking/Canonization su una base di conoscenza come ad esempio wikidata.\n",
    "Possiamo iniziare a pensare un sistema semplice per questa attività utilizzando un classificatore a finestra mediante un classificatore logistico binario.\n",
    "\n",
    "L'idea è quella di addestrare un classificatore logistico binario, su un insieme di dati classificati a mano in modo da classificare la parola centrale (si/no) utilizzando le parole della finestra, di solito le classi sono più di una ma per il momento teniamo semplice il problema\n",
    "\n",
    "**Esempio:** vogliamo classificare la parola Paris come entità location in un contesto con una finestra di dimensione 2 della frase: the museum in Paris are amazing to see.\n",
    "\n",
    "La finestra per Paris sarà: $X_{window} = [x_{museum},x_{in},x_{Paris},x_{are},x_{amazing}]^{T}$ con $X_{window} \\in \\mathbb{R} ^ {5d}$ vettore colonna.\n",
    "\n",
    "Questo vettore verrà poi usato nella rete neuroale, per eseguire la classificazione.\n",
    "I dati con cui avremo a che fare non saranno separabili linearmente, Le reti neuronali sono una famiglia di classificatori non lineari, questa è l'abilità delle reti neuronali.\n",
    "\n",
    "![linear vs non linear](./images/linear_non_linear.png)\n",
    "\n",
    "## Il neurone\n",
    "\n",
    "Un neurone rappresenta una unità di calcolo che prende in ingresso $n$ valori di input e produce un valore di output. Quello che differenzia un neurone da un altro sono i loro parametri (detti anche pesi). Una delle scelte più popolari per i neuroni è il \"sigmoide\" o \"regressione logistica\". Questa unità prende un vettore $n$-dimensionale $x$ e produce un valore scalare $a$. \n",
    "Questo neurone è associato ad un vettore $w$ a $n$-dimensioni di pesi e un valore scalare di bias $b$. \n",
    "\n",
    "Il valore $a$ risultato è dato da:\n",
    "\n",
    "$$\n",
    "a = \\frac{1}{1 + e^{-(w^{\\top}x + b)}}\n",
    "$$\n",
    "\n",
    "possiamo combinare pesi e bias con la formula equivalente:\n",
    "\n",
    "$$\n",
    "a = \\frac{1}{1 + e^{-([w^{\\top} \\space b] \\cdot [x \\space 1])}}\n",
    "$$\n",
    "\n",
    "## Singolo livello di neuroni\n",
    "\n",
    "Estendiamo l'idea e moltiplichiamo il numero di neuroni, in questo caso il vettore $x$ andrà a alimentare una serie di neuroni. \n",
    "Se ci riferiamo ai pesi degli stessi come $\\{ w^1, \\cdots, w^{n} \\}$ e ai bias come  $\\{ b_1, \\cdots, b_{n} \\}$ otteremo i rispettivi risultati come $\\{ a_1, \\cdots, a_{n} \\}$\n",
    "\n",
    "$$\n",
    "a_1 = \\frac{1}{1 + e^{-(w^{1 \\top}x + b_1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_n = \\frac{1}{1 + e^{-(w^{n \\top}x + b_n)}}\n",
    "$$\n",
    "\n",
    "Usiamo dunque la seguente notazione per tenere semplici le notazioni:\n",
    "\n",
    "$$\\sigma(z) = \\begin{bmatrix} \\frac{1}{1 + exp(z_1)} \\\\ \\vdots \\\\  \\frac{1}{1 + exp(z_m)} \\\\ \\end{bmatrix}$$\n",
    "\n",
    "$$b =  \\begin{bmatrix} b_1  \\\\ \\vdots \\\\ b_n \\end{bmatrix} \\in \\mathbb{R}^m$$\n",
    "\n",
    "$$W =  \\begin{bmatrix} w^{1 \\top}  \\\\ \\vdots \\\\  w^{n \\top} \\end{bmatrix} \\in \\mathbb{R}^{m \\times n}$$\n",
    "\n",
    "Possiamo scrivere il risultato come della moltiplicazione e della somma con il bias come:\n",
    "\n",
    "$$z = Wx + b$$\n",
    "\n",
    "Il risultato della funzione sigmoide può essere scritto come:\n",
    "\n",
    "$$\\sigma(z) = \\sigma(Wx + b)$$\n",
    "\n",
    "Quindi questa combinazione di funzioni di attivazione cosa ci dicono? Possiamo pensarle come indicatori di presenza di alcune combinazioni pesate delle features. Possiamo usare queste combinazioni per effettuare attività come ad esempio la classificazione.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2330f9",
   "metadata": {},
   "source": [
    "## Calcolo del Feed Foward\n",
    "\n",
    "Abbiamo appena visto come un vettore $x \\in \\mathbb{R}^{n}$ può essere usato per alimentare una serie di neuroni e per creare il vettore $a \\in \\mathbb{R}^{m}$. Ma perchè dovremmo farlo ? Riprendiamo il nostro problema di classificare la parola \"Paris\" nel contesto:\n",
    "\n",
    "\"Museums in Paris are amazing\"\n",
    "\n",
    "In questi casi non vogliamo solo catturare il significato della parola centrale ma vogliamo analizzare le interazioni delle parole al fine di classificare correttamente la parola.\n",
    "Ad esempio quanto dovrebbe importare \"Museum\" se la seconda parola è \"in\". Queste relazioni non lineari spesso non vengono catturate usando solamente una funzione Softmax, ma hanno la necessità di \"lavorazioni\" intermedie. \n",
    "\n",
    "Possiamo quindi usare un'altra matrice $U \\in \\mathbb{R}^{m \\times 1}$ per generare un punteggio non normalizzato per la nostra attività di classificazione.\n",
    "\n",
    "$$\n",
    "s = U^{T} a = U^{T} f(Wx + b)\n",
    "$$\n",
    "\n",
    "Dove $f$ rappresenta la funzione di attivazione.\n",
    "\n",
    "**Analisi di dimensionalità**: Se rappresentiamo ogni word vector con un vettore di dimensione 4 e usiamo una finestra di 5 parole, il nostro vettore $x \\in \\mathbb{R}^{20}$ se usiamo un livello di attivazione con 8 unità e un valore singolo di uscita, score. Dunque avremo che $W \\in \\mathbb{R}^{8 \\times 20}$, $b \\in \\mathbb{R}^{8}$, $U \\in \\mathbb{R}^{8 \\times 1}$, $s \\in \\mathbb{R}$\n",
    "\n",
    "### Funzione obiettivo massimo margine\n",
    "Come in molti modelli di machine learning, anche le reti neuronali hanno bisogno di una funzione obiettivo.\n",
    "Questa rappresenta una misura dell'errore o della bontà del nostro sistema di cui rispettivamente vogliamo minimizzare/massimizzare il valore. Discuteremo su una delle più popolari metriche di errore conosciuta anche come obiettivo di massimo margine. L'idea principale dietro a questo il punteggio associato ai dati etichettati come \"true\" sia più grande dei dati etichettati come \"false\".\n",
    "\n",
    "Usiamo l'esempio precedente se impostiamo $s$ per calcolare il punteggio della finestra \"true\" \"Museum in Paris are Amazing\" e impostiamo $s_c$ il punteggio della finestra \"false\" \"Not all museum in Paris\" (la c sta ad indicare che la finestra è corrotta).\n",
    "Allora la nostra funzione obiettivo che vorremmo massimizzare sarà $(s - s_c)$  mentre il risultato che vorremo minimizzare sarà $(s_c - s)$ . Comunque modificheremo la funzione per assicurarci che gli errori siano calcolati solo se $s_c > s \\Rightarrow (s_c - s) > 0$, stiamo dicendo che ci interessa il dato $s_c$ solo se è maggiore del dato $s$. \n",
    "\n",
    "Il nostro calcolo sarà $(s_c - s)$ se $s_c > s$ altrimenti avremo come valore $0$.\n",
    "\n",
    "Modifichiamo dunque la funzione obiettivo nel seguente modo:\n",
    "\n",
    "$minimize J = max(s_c - s,0)$\n",
    "\n",
    "L'ottimizzazione sopra è un pochino rischiosa in quanto vorremmo avere un margine di sicurezza, vogliamo dunque valutare un punto come \"true\" se questo supera lo score del \"false\" più un certo margine positivo $\\Delta$.\n",
    "\n",
    "In altre parole la nostra funzione obiettivo diventerà:\n",
    "\n",
    "$minimize J = max(\\Delta + s_c - s,0)$\n",
    "\n",
    "In base alle nostre formulazioni abbiamo che:\n",
    "\n",
    "* $s_c =  U^{T} f(Wx_c + b)$\n",
    "* $s   =  U^{T} f(Wx + b)$\n",
    "\n",
    "## Backpropagation basi\n",
    "\n",
    "In questa sezione discutiamo come effettuare la fase di training dei differenti parametri del modello quando il costo J discusso nella sezione precedente sia positiva.\n",
    "\n",
    "Come prima osservazione non dovremo fare nessuna ottimizzazione se il costo è 0. \n",
    "Dal momento che in genere usiamo SGD per aggiornare i pesi abbiamo la necessita calcolare il gradiente:\n",
    "\n",
    "$\\sigma^{(t+1)} = \\sigma^{(t)} - \\alpha \\Delta_{\\sigma^{(t)}}J $\n",
    "\n",
    "La Backpropagation è una tecnica che permette di usare la regola di derivazione per calcolare il loss gradient di ogni parametro. Per capire meglio useremo una rete giocattolo come nella immagine qui sotto:\n",
    "\n",
    "![toy](./images/toy_network.png)\n",
    "\n",
    "Utilizzeremo una rete neuronale con un singolo livello nascosto e un singolo valore di uscita. Stabiliamo una notazione che ci permetterà di generalizzare il modello successivamente.\n",
    "\n",
    "* $x_i$ rappresenta l'input della rete\n",
    "* $s$ rappresenta l'output della rete\n",
    "* ogni livello (includendo il layer di input e output) ha neuroni che ricevono i dati di input ed elaborano un valore di output. il j-esimo neurone del livello k riceve il valore scalare $z_{j}^{k}$ e produce un valore scalare di attivazione $a_{j}^{k}$\n",
    "* chiamiamo l'errore di backpropagation calcolato al punto $z_{j}^{k}$ come $\\delta_{j}^{k}$\n",
    "* $W^k$ è la matrice di trasferimento che mappa l'input dal k-esimo livello al livello successivo k+1 \n",
    "\n",
    "**Inziamo con il ragionamento:** supponiamo che il costo $J = (1 + s_c - s)$ sia positivo e che vogliamo aggiornare il peso $W^{1}_{(1,4)}$ \n",
    "\n",
    "![toy](./images/toy_network1.png)\n",
    "\n",
    "questo contribuisce a $z^{2}_{1}$ e di conseguenza a $a^{2}_{1}$, questo fatto è cruciale per comprendere come funziona la backpropagation e come i gradienti retropropagati sono influenzati solo dai valori a cui contribuiscono.\n",
    "Successivamente $a^{2}_1$ viene usato per proseguire il calcolo tramite la moltiplicazione con $W^{2}_1$.\n",
    "\n",
    "Riprendendo l'immagine sopra, in merito all'aggiornamento di $W_{(1,4)}^{1}$ possiamo dire che:\n",
    "\n",
    "1. Partiamo con un segnale di errore 1 che si propaga all'indietro da $a_{1}^{3}$\n",
    "2. Moltiplichiamo poi questo errore per il gradiente locale che mappa $z_{1}^{3}$ verso $a_{1}^{3}$ supponendo che $\\delta_{1}^{3}$ sia pari ad 1 avremo come risultato 1\n",
    "3. A questo punto il segnale di errore raggiunge $z_{1}^{3}$ ora dobbiamo ridistribuire il segnale di errore affinchè la \"giusta quota\" arrivi verso $a_{1}^{2}$\n",
    "4. L'errore a questo punto della rete è  $z_{1}^{3} \\times W_1^{2} = W_1^{2}$\n",
    "5. Come fatto prima dobbiamo al passo 2 dobbiamo passare l'errore attraverso il neurone che mappa $z_1^{2}$ verso $a_1^{2}$. Facciamo questo moltiplicando il segnale di errore $a_1^{2}$ con il gradiente locale del neurone $f'(z_1^{2})$\n",
    "6. Ora il segnale di errore a $z_1^{2}$ è $f'(z_1^{2}) W_{1}^{2}$ nota come $\\delta_{1}^{2}$.\n",
    "7. Finalmente dobbiamo distribuire equamente la quota dell'errore verso $W_{1,4}^{1}$ semplicemente moltiplicandolo per l'input come capita $a_{4}^{1}$\n",
    "8. Dunque il gradiente rispetto $W_{1,4}^{1}$ calcolato come $a_{4}^{1}f'(z_1^{2}) W_{1}^{2}$\n",
    "\n",
    "**Aggiornamento dei BIAS:** i termini bias come ad esempio $b_{1}^{1}$ sono matematicamente equivalenti al contributo degli altri pesi\n",
    "\n",
    "### Aggiornamento dei pesi vettorializzato\n",
    "\n",
    "Abbiamo discusso come eseguire l'aggiornamento di un peso. Ora affrontiamo il problema dell'aggiornamento, aggiornando le matrici dei pesi e il vettore dei bias in un colpo solo.\n",
    "Nota che questa è una estensione di quanto detto sopra e ci aiuterà a comprendere su come l'aggiornamento dei peso può essere fatto in modo matriciale.\n",
    "\n",
    "Per un qualsiasi parametro $W_{(i,j)}^{k}$ abbiamo calcolato che l'errore del gradiente è semplicemente $\\delta_{i}^{k+1} \\cdot a_{j}^{k}$. Ricorda che ma matrice $W^{k}$ è la matrice che mappa $a^{k}$ verso $z^{(k+1)}$.\n",
    "\n",
    "Possiamo dunque calcolare l'intera matrice di aggiornamento:\n",
    "\n",
    "![gradient](./images/gradient_matrix.png)\n",
    "\n",
    "\n",
    "Questo può essere calcolato usando il prodotto esterno usando il vettore errore e il vettore delle attivazioni.\n",
    "\n",
    "### Suggerimenti e trucchi\n",
    "\n",
    "Abbiamo affrontato le basi delle reti neuronali, vediamo ora alcuni trucchi comunemente usati in pratica.\n",
    "\n",
    "#### Controllo del gradiente\n",
    "\n",
    "Abbiamo discusso come calcolare il gradiente in modo analitico, affrontiamo ora l'aspetto dell'approssimazione numerica.\n",
    "Questo metodo può risultare computazionalmente inefficiente per essere usato nel training, questo metodo può essere utile per effettuare controlli di correttezza della nostra derivata analitica.\n",
    "\n",
    "Dato un modello con un vettore di parametri $\\theta$ e una funzione loss $J$ il gradiente numerico attorno al punto $\\theta_{i}$ può essere calcolato tramite la **differenza finita centrata**:\n",
    "\n",
    "$$f'(\\theta) \\approx \\frac{J(\\theta)^{(i+)} - J(\\theta)^{(i-)}}{2 \\epsilon}$$\n",
    "\n",
    "dove $\\epsilon$ è un numero piccolo (tipicamente attorno al valore $1e^{-5}$). Il termine $J(\\theta)^{(i+)}$ rappresenta l'errore calcolato un passo in avanti per un dato input, quando perturbiamo l'i-esimo elemento di $+\\epsilon$. Specularmente facciamo lo stesso per l'elemento $J(\\theta)^{(i-)}$.\n",
    "\n",
    "Questa definizione deriva naturalmente dalla sua definizione scalare:\n",
    "\n",
    "$$f'(x) \\approx \\frac{f(x + \\epsilon) - f(x)}{\\epsilon}$$\n",
    "\n",
    "Ora una domanda naturale viene spontanea, se questo metodo è preciso e affidabile perchè non potremmo usare questo per calcolare il gradiente?.\n",
    "\n",
    "La risposta semplice è che come suggerito prima questo metodo è ineffiente. Ricorda che per calcolare il gradiente rispetto ad un elemento dobbiamo fare due passi di forward della rete in avanti, queste rende l'ottimizzazione particolarmente costosa.\n",
    "Le reti moderne contengono milioni di parametri e calcolare due passi di forward per ogni parametro rende questo un metodo chiaramente non ottimale.\n",
    "\n",
    "Questa inefficienza spiega perchè usiamo il gradient check per verificare il corretto calcolo del gradiente in modo analitico, che è più veloce da calcolare.\n",
    "\n",
    "Una implementazione standard del gradient check può essere fatta nel seguente modo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d26e4",
   "metadata": {},
   "source": [
    "```{python}\n",
    "    def eval_numerical_gradient(f, x):\n",
    "        \"\"\"\n",
    "        a naive implementation of numerical gradient of f at x\n",
    "        - f should be a function that takes a single argument\n",
    "        - x is the point (numpy array) to evaluate the gradient\n",
    "        at\n",
    "        \"\"\"\n",
    "        \n",
    "        fx = f(x) # evaluate function value at original point\n",
    "        grad = np.zeros(x.shape)\n",
    "        h = 0.00001\n",
    "        \n",
    "        # iterate over all indexes in x\n",
    "        it = np.nditer(x, flags=[’multi_index’],\n",
    "            op_flags=[’readwrite’])\n",
    "            \n",
    "        while not it.finished:\n",
    "            # evaluate function at x+h\n",
    "            ix = it.multi_index\n",
    "            old_value = x[ix]\n",
    "            x[ix] = old_value + h # increment by h\n",
    "            fxh_left = f(x) # evaluate f(x + h)\n",
    "            x[ix] = old_value - h # decrement by h\n",
    "            fxh_right = f(x) # evaluate f(x - h)\n",
    "            x[ix] = old_value # restore to previous value (very important!)\n",
    "            # compute the partial derivative\n",
    "            grad[ix] = (fxh_left - fxh_right) / (2*h) # the slope\n",
    "            it.iternext() # step to next dimension\n",
    "        return grad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea555dfb",
   "metadata": {},
   "source": [
    "### Regolarizzazione\n",
    "\n",
    "Come in molti modelli di machine learning, le reti neuronali sono prone al problema di overfitting.\n",
    "Questo fa si che il modello ottenga dei perfetti risultati sul dataset di training, ma che perda la sua abilità di generalizzare.\n",
    "\n",
    "\n",
    "Una tecnica comune per indirizzare l'overfitting (problema conosciuto anche come \"alta varianza\") è quello di incorporare la regolarizzazione L2. L'idea è quella di aggiungere un termine extra per la nostra funzione loss $J$ ora il costo totale viene calcolato come:\n",
    "\n",
    "$$J_R = J + \\lambda \\sum_{i=1}^{L} \\lVert W^{(i)} \\rVert_F$$\n",
    "\n",
    "nella formula sopra $\\lVert W^{(i)} \\rVert_F$ rappresenta la norma della matrice $W^{(i)}$ la i-esima matrice della rete neuronale. e $\\lambda$ rappresenta un iperparametro che controlla quanto pesa la regolarizzazione nel calcolo del costo.\n",
    "\n",
    "Siccome stiamo provando a minimizzare il costo $J_R$ il risultato sarà la penalizzazione dei pesi con un valore grande.Questo porta ad una riduzione del problema di overfitting. \n",
    "\n",
    "Scegliere il giusto valore di $\\lambda$ è una operazione critica e deve essere scelta tramite hyper parameter tuning. \n",
    "Un valore troppo alto di $\\lamda$ comporta che i pesi saranno vicini al valore zero, con il risultato che il modello non imparerà nulla dai dati di training (Underfitting). Al contrario se il parametro è troppo basso torniamo al problema principale di overfitting.\n",
    "\n",
    "Nota che i termini di bias non sono regolarizzati e non contribuiscono al calcolo [qui](https://stats.stackexchange.com/questions/153605/no-regularisation-term-for-bias-unit-in-neural-network) la spiegazione del perchè.\n",
    "\n",
    "Ci sono altri tipi di regolarizzazione, ad come ad esempio regolarizzazione $L_{1}$ che è la somma di tutti i valori assoluti dei pesi. Questo tipo di normalizzazione non viene usato in pratica in quanto porta alla sparsità dei pesi.\n",
    "\n",
    "Nella prossima sezione discuteremo del *dropout* che agisce come un'altra forma di regolarizzazione spegnendo casualmente i neuroni nel passo foward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31745d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
